{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import NearestNDInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Land Mask creation\n",
    "# global_coords = (-180, 180, -90, 90)  # (lon_min, lon_max, lat_min, lat_max). Not used.\n",
    "# med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "tmask = xr.open_dataset('dati/mist/tmask_interpolated.nc')\n",
    "\n",
    "ocean_mask = np.flipud(tmask['tmask'])   # Extract the sst data (flipped correctly)\n",
    "print(ocean_mask.shape)\n",
    "plt.imshow(ocean_mask)\n",
    "\n",
    "italy_mask = ocean_mask[0:256, 310:566]    # Focus on italy, 0 for land, 1 for sea\n",
    "italy_mask = italy_mask.astype(bool)\n",
    "print(italy_mask.shape)\n",
    "plt.imshow(italy_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "files_y2002_2004c = glob.glob('dati/y2002_2004c/*.nc')\n",
    "files_y2005_2009c = glob.glob('dati/y2005_2009c/*.nc')\n",
    "files_y2010_2014c = glob.glob('dati/y2010_2014c/*.nc')\n",
    "files_y2015_2019c = glob.glob('dati/y2015_2019c/*.nc')\n",
    "files_y2020_2023c = glob.glob('dati/y2020_2023c/*.nc')\n",
    "all_files = files_y2002_2004c + files_y2005_2009c + files_y2010_2014c + files_y2015_2019c + files_y2020_2023c\n",
    "\n",
    "\n",
    "# Datasets and dates lists, for day and night\n",
    "dataset_d = []; date_d = []\n",
    "dataset_n = []; date_n = []\n",
    "\n",
    "qual_d = []; qual_n = []\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    # Check if the dataset is day or night by checking the variable name: 'sst' for day, 'sst4' for night\n",
    "    if 'sst' in ds:\n",
    "        data = ds['sst'].values[0:256, 310:566]\n",
    "        data = np.where(italy_mask, data, np.nan)    # Cut away measurements of lakes and rivers\n",
    "\n",
    "        qual = ds['qual_sst'].values[0:256, 310:566]\n",
    "        qual = np.where(italy_mask, qual, np.nan)\n",
    "\n",
    "        # Extract the date from the product name. Example: AQUA_MODIS.20030722.L3m.DAY.SST.x_sst.nc\n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()    # Use the date in the file name for day data\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "\n",
    "        # Append the data and the date to the respective lists\n",
    "        dataset_d.append(data)\n",
    "        date_d.append(date)\n",
    "        qual_d.append(qual)\n",
    "        \n",
    "    else:\n",
    "        data = ds['sst4'].values[0:256, 310:566]\n",
    "        data = np.where(italy_mask, data, np.nan)\n",
    "\n",
    "        qual = ds['qual_sst4'].values[0:256, 310:566]\n",
    "        qual = np.where(italy_mask, qual, np.nan)\n",
    "        \n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "        \n",
    "        dataset_n.append(data)\n",
    "        date_n.append(date)\n",
    "        qual_n.append(qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dataset_d = np.array(dataset_d)\n",
    "date_d = np.array(date_d)\n",
    "dataset_n = np.array(dataset_n)\n",
    "date_n = np.array(date_n)\n",
    "\n",
    "qual_d = np.array(qual_d)\n",
    "qual_n = np.array(qual_n)\n",
    "\n",
    "print(dataset_d.shape)\n",
    "print(date_d.shape)\n",
    "print(dataset_n.shape)\n",
    "print(date_n.shape)\n",
    "\n",
    "print(qual_d.shape)\n",
    "print(qual_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count quality levels over both day and night data\n",
    "\n",
    "def analyze_quality(qual_array):\n",
    "    # Flatten the array to make counting easier\n",
    "    flattened = qual_array.flatten()\n",
    "    \n",
    "    # Count the total number of valid (non-NaN) datapoints\n",
    "    total_valid = np.count_nonzero(~np.isnan(flattened))\n",
    "    \n",
    "    # Initialize a dictionary to hold counts and percentiles for each quality level\n",
    "    quality_counts = {i: np.count_nonzero(flattened == i) for i in range(6)}\n",
    "    quality_percentiles = {i: (quality_counts[i] / total_valid) * 100 for i in range(6)}\n",
    "    \n",
    "    return quality_counts, quality_percentiles\n",
    "\n",
    "# Analyze quality for qual_d and qual_n\n",
    "quality_counts_d, quality_percentiles_d = analyze_quality(qual_d)\n",
    "quality_counts_n, quality_percentiles_n = analyze_quality(qual_n)\n",
    "\n",
    "# Print the results\n",
    "print(\"Quality counts for qual_d:\", quality_counts_d)\n",
    "print(\"Quality percentiles for qual_d:\", quality_percentiles_d)\n",
    "print(\"Quality counts for qual_n:\", quality_counts_n)\n",
    "print(\"Quality percentiles for qual_n:\", quality_percentiles_n)\n",
    "\n",
    "# ======\n",
    "\n",
    "# Combine the day and night datasets and dates into one dataset and date array\n",
    "dataset_total = np.concatenate((dataset_d, dataset_n), axis=0)\n",
    "date_total = np.concatenate((date_d, date_n), axis=0)\n",
    "qual_total = np.concatenate((qual_d, qual_n), axis=0)\n",
    "\n",
    "#test qual_total\n",
    "quality_counts_total, quality_percentiles_total = analyze_quality(qual_total)\n",
    "print(\"Quality counts for qual_total:\", quality_counts_total)\n",
    "print(\"Quality percentiles for qual_total:\", quality_percentiles_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
