{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "from scipy.interpolate import NearestNDInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmask:producer = CMCC - ROFS division ;\n",
    "# tmask:machine = juno ;\n",
    "# tmask:source mesh = /data/opa/mfs/Med_static/MFS_EAS8_STATIC_V1/NEMO_DATA0/mesh_mask.nc ;\n",
    "# tmask:method = scipy.interpolate.griddata w/ nearest option ;\n",
    "# tmask:created = 2024-04-24 16:33:47.071164 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Land Mask creation\n",
    "# global_coords = (-180, 180, -90, 90)  # (lon_min, lon_max, lat_min, lat_max). Not used.\n",
    "# med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "tmask = xr.open_dataset('dati/mist/tmask_interpolated.nc')\n",
    "\n",
    "ocean_mask = np.flipud(tmask['tmask'])   # Extract the sst data (flipped correctly)\n",
    "print(ocean_mask.shape)\n",
    "plt.imshow(ocean_mask)\n",
    "plt.show()\n",
    "\n",
    "italy_mask = ocean_mask[0:256, 310:566]    # Focus on italy, 0 for land, 1 for sea\n",
    "italy_mask = italy_mask.astype(bool)\n",
    "print(italy_mask.shape)\n",
    "plt.imshow(italy_mask)\n",
    "plt.show()\n",
    "\n",
    "#np.save('dati/mist/mediterrean_mask.npy', ocean_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old Land Mask creation, DO NOT USE\n",
    "global_coords = (-180, 180, -90, 90)  # (lon_min, lon_max, lat_min, lat_max). Not used.\n",
    "med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "avg_ds = xr.open_dataset('dati/mist/AQUA_MODIS.20020704_20231231.L3m.CU.SST.sst.4km.nc')   # Average data\n",
    "avg_data = avg_ds['sst']   # Extract the sst variable\n",
    "mediterrean_avg_data = avg_data.sel(lon=slice(med_coords[0], med_coords[1]), lat=slice(med_coords[3], med_coords[2]))\n",
    "old_ocean_mask = xr.where(mediterrean_avg_data.isnull(), 0, 1)    # Create a binary land-sea mask (0 for land, 1 for sea)\n",
    "old_italy_mask = old_ocean_mask[0:256, 310:566]    # Focus on italy, 0 for land, 1 for sea\n",
    "\n",
    "#plot italy_mask, old_italy_mask, and their differences\n",
    "difference_mask = old_italy_mask - italy_mask\n",
    "plt.imshow(difference_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "files_y2002_2004c = glob.glob('dati/y2002_2004c/*.nc')\n",
    "files_y2005_2009c = glob.glob('dati/y2005_2009c/*.nc')\n",
    "files_y2010_2014c = glob.glob('dati/y2010_2014c/*.nc')\n",
    "files_y2015_2019c = glob.glob('dati/y2015_2019c/*.nc')\n",
    "files_y2020_2023c = glob.glob('dati/y2020_2023c/*.nc')\n",
    "all_files = files_y2002_2004c + files_y2005_2009c + files_y2010_2014c + files_y2015_2019c + files_y2020_2023c\n",
    "\n",
    "\n",
    "# Datasets and dates lists, for day and night\n",
    "dataset_d = []; date_d = []\n",
    "dataset_n = []; date_n = []\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    # Check if the dataset is day or night by checking the variable name: 'sst' for day, 'sst4' for night\n",
    "    if 'sst' in ds:\n",
    "        data = ds['sst'].values[0:256, 310:566]\n",
    "        data = np.where(italy_mask, data, np.nan)    # Cut away measurements of lakes and rivers\n",
    "        # Extract the date from the product name. Example: AQUA_MODIS.20030722.L3m.DAY.SST.x_sst.nc\n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()    # Use the date in the file name for day data\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "\n",
    "        # Append the data and the date to the respective lists\n",
    "        dataset_d.append(data)\n",
    "        date_d.append(date)\n",
    "        \n",
    "    else:\n",
    "        data = ds['sst4'].values[0:256, 310:566]\n",
    "        data = np.where(italy_mask, data, np.nan)\n",
    "        \n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "        \n",
    "        dataset_n.append(data)\n",
    "        date_n.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dataset_d = np.array(dataset_d)\n",
    "date_d = np.array(date_d)\n",
    "dataset_n = np.array(dataset_n)\n",
    "date_n = np.array(date_n)\n",
    "\n",
    "print(dataset_d.shape)\n",
    "print(date_d.shape)\n",
    "print(dataset_n.shape)\n",
    "print(date_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the min and max measurements in the whole dataset\n",
    "\n",
    "data_min = min(np.nanmin(dataset_d), np.nanmin(dataset_n))\n",
    "data_max = max(np.nanmax(dataset_d), np.nanmax(dataset_n))\n",
    "print(data_min)\n",
    "print(data_max)\n",
    "\n",
    "# print(date_d[0], date_d[-1])\n",
    "# print(date_n[0], date_n[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save absolute values before normalization\n",
    "\n",
    "abs_dataset_d = dataset_d\n",
    "abs_dataset_n = dataset_n\n",
    "\n",
    "np.save('dati/mist/datasets/abs_dataset_d.npy', abs_dataset_d)\n",
    "np.save('dati/mist/datasets/abs_dataset_n.npy', abs_dataset_n)\n",
    "np.save('dati/mist/datasets/date_d.npy', date_d)\n",
    "np.save('dati/mist/datasets/date_n.npy', date_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min of day:', np.nanmin(dataset_d))\n",
    "print('avg of day:', np.nanmean(dataset_d))\n",
    "print('max of day:', np.nanmax(dataset_d))\n",
    "\n",
    "print('min of night:', np.nanmin(dataset_n))\n",
    "print('avg of night:', np.nanmean(dataset_n))\n",
    "print('max of night:', np.nanmax(dataset_n))\n",
    "\n",
    "print('minimum temperature:', data_min, 'maximum temperature:', data_max)\n",
    "\n",
    "# print('min of day:', np.nanmin(abs_dataset_d))\n",
    "# print('avg of day:', np.nanmean(abs_dataset_d))\n",
    "# print('max of day:', np.nanmax(abs_dataset_d))\n",
    "\n",
    "# print('min of night:', np.nanmin(abs_dataset_n))\n",
    "# print('avg of night:', np.nanmean(abs_dataset_n))\n",
    "# print('max of night:', np.nanmax(abs_dataset_n))\n",
    "\n",
    "# print('minimum temperature:', data_min, 'maximum temperature:', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset in the range [-1, 1]\n",
    "\n",
    "dataset_d = 2 * ((dataset_d - data_min) / (data_max - data_min)) - 1\n",
    "dataset_n = 2 * ((dataset_n - data_min) / (data_max - data_min)) - 1\n",
    "\n",
    "# Alternative: normalize it in the range [-2, 45]\n",
    "\n",
    "# temperature_min = -2\n",
    "# temperature_max = 45\n",
    "# dataset = np.clip(dataset, temperature_min, temperature_max)\n",
    "# normalized_dataset = (dataset - temperature_min) / (temperature_max - temperature_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normalized min of day:', np.nanmin(dataset_d))\n",
    "print('normalized avg of day:', np.nanmean(dataset_d))\n",
    "print('normalized max of day:', np.nanmax(dataset_d))\n",
    "\n",
    "print('normalized min of night:', np.nanmin(dataset_n))\n",
    "print('normalized avg of night:', np.nanmean(dataset_n))\n",
    "print('normalized max of night:', np.nanmax(dataset_n))\n",
    "\n",
    "print('minimum temperature:', data_min, 'maximum temperature:', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unite the day and night datasets\n",
    "\n",
    "# dataset = np.concatenate((dataset_d, dataset_n), axis=0)\n",
    "# date = np.concatenate((date_d, date_n), axis=0)\n",
    "\n",
    "# print(dataset.shape)\n",
    "# print(date.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE CREATION\n",
    "# Create the baseline arrays\n",
    "baseline_d = np.empty((366, 256, 256))\n",
    "baseline_n = np.empty((366, 256, 256))\n",
    "\n",
    "# Convert the date arrays to pandas DatetimeIndex with datetime format, then get the day of the year for each date\n",
    "date_series_d = pd.to_datetime(date_d, unit='D', origin=pd.Timestamp('1970-01-01'))\n",
    "day_of_year_d = date_series_d.dayofyear\n",
    "date_series_n = pd.to_datetime(date_n, unit='D', origin=pd.Timestamp('1970-01-01'))\n",
    "day_of_year_n = date_series_n.dayofyear\n",
    "\n",
    "# For each day of the year, calculate the average temperature for day, night, and general\n",
    "for day in range(0, 366):\n",
    "    # Get the indices of the dates that match the current day of the year for day, night, and general\n",
    "    indices_d = np.where(day_of_year_d == day+1)    # Add 1 to day because day_of_year starts from 1\n",
    "    indices_n = np.where(day_of_year_d == day+1)\n",
    "    indices = np.where(day_of_year_d == day+1)\n",
    "    \n",
    "    # Calculate the average temperature for the current day of the year for day, night, and general, ignoring absent days\n",
    "    mean_temp_d = np.nanmean(dataset_d[indices_d], axis=0) if indices_d[0].size > 0 else np.nan\n",
    "    mean_temp_n = np.nanmean(dataset_n[indices_n], axis=0) if indices_n[0].size > 0 else np.nan\n",
    "        \n",
    "    # Assign the mean temperatures to the baseline arrays\n",
    "    baseline_d[day] = mean_temp_d\n",
    "    baseline_n[day] = mean_temp_n\n",
    "\n",
    "\n",
    "# Create a meshgrid for the x and y coordinates, to be used in the interpolation\n",
    "x = np.arange(256)\n",
    "y = np.arange(256)\n",
    "xx, yy = np.meshgrid(x, y)  # Grid of x, y coordinates\n",
    "\n",
    "\n",
    "# For all NaN values still present in the ocean, interpolate spatially\n",
    "for day in range(366):\n",
    "    for baseline_array in [baseline_d, baseline_n]:\n",
    "        # Get the current baseline and create a mask for the valid values\n",
    "        data = baseline_array[day]\n",
    "        valid_mask = ~np.isnan(data) #& italy_mask\n",
    "\n",
    "        # Get the valid values and their coordinates\n",
    "        values = data[valid_mask]\n",
    "        coords = np.array((xx[valid_mask], yy[valid_mask])).T   # Coordinates of the non-nan values, transposed back in 2D\n",
    "\n",
    "        # Perform the interpolation only on the ocean pixels (italy_mask)\n",
    "        data_interp = griddata(coords, values, (xx[italy_mask], yy[italy_mask]), method='linear')\n",
    "        # Assign the interpolated data back to the ocean pixels in the baseline array\n",
    "        baseline_array[day, italy_mask] = data_interp\n",
    "\n",
    "        # Perform a nearest-neighbor interpolation to fill in any remaining NaN values\n",
    "        valid_mask = ~np.isnan(baseline_array[day]) #& italy_mask\n",
    "        values = baseline_array[day, valid_mask]\n",
    "        coords = np.array((xx[valid_mask], yy[valid_mask])).T\n",
    "        interpolator = NearestNDInterpolator(coords, values)    # Nearest-neighbor interpolator\n",
    "        baseline_array[day, italy_mask] = interpolator((xx[italy_mask], yy[italy_mask]))    # Interpolation and assignment\n",
    "\n",
    "\n",
    "# Put the value 0 in the land pixels of the baseline arrays\n",
    "baseline_d[:, ~italy_mask] = 0\n",
    "baseline_n[:, ~italy_mask] = 0\n",
    "\n",
    "print(baseline_d.shape)\n",
    "print(baseline_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of the baseline for a few days of the year\n",
    "\n",
    "# Create a dictionary to map the day numbers to the full names of the days and months. Used only for visualization purposes. 2020 is a leap year so we also get the 366th day\n",
    "day_names = {i: (datetime.datetime(2020, 1, 1) + datetime.timedelta(days=i-1)).strftime('%d %B') for i in range(1, 367)}\n",
    "\n",
    "# Define the days to plot\n",
    "days_to_plot = [1, 60, 199, 366]  # 1st of January, 29th of February, 17th of July, 31st of December\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(15, 20))  # Create a 4x2 grid of subplots\n",
    "\n",
    "# For each day to plot\n",
    "for i, day in enumerate(days_to_plot):\n",
    "    # Plot the day baseline for the day\n",
    "    im_d = axs[i, 0].imshow(baseline_d[day-1], cmap='viridis')  # Subtract 1 from day because jan 1 is index 0 in the baseline array\n",
    "    axs[i, 0].set_title(f'Day {day_names[day]}')\n",
    "    fig.colorbar(im_d, ax=axs[i, 0])\n",
    "    \n",
    "    # Plot the night baseline for the day\n",
    "    im_n = axs[i, 1].imshow(baseline_n[day-1], cmap='viridis')  # Subtract 1 from day because jan 1 is index 0 in the baseline array\n",
    "    axs[i, 1].set_title(f'Night {day_names[day]}')\n",
    "    fig.colorbar(im_n, ax=axs[i, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG : Iterate over the baseline arrays and check if there are still NaN values\n",
    "# for i, baseline_array in enumerate([baseline_d, baseline_n]):\n",
    "#     for day in range(baseline_array.shape[0]):\n",
    "#         if np.isnan(baseline_array[day]).any():\n",
    "#             print(f'NaN value found in baseline_array {i} on day {day}')\n",
    "#             plt.imshow(baseline_array[day])\n",
    "#             plt.colorbar()\n",
    "#             plt.title(f'Baseline_array {i} on day {day}')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABS baseline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ABS baseline arrays\n",
    "abs_baseline_d = np.empty((366, 256, 256))\n",
    "abs_baseline_n = np.empty((366, 256, 256))\n",
    "\n",
    "# Convert the date arrays to pandas DatetimeIndex with datetime format, then get the day of the year for each date\n",
    "date_series_d = pd.to_datetime(date_d, unit='D', origin=pd.Timestamp('1970-01-01'))\n",
    "day_of_year_d = date_series_d.dayofyear\n",
    "date_series_n = pd.to_datetime(date_n, unit='D', origin=pd.Timestamp('1970-01-01'))\n",
    "day_of_year_n = date_series_n.dayofyear\n",
    "\n",
    "\n",
    "# For each day of the year, calculate the average temperature for day and night\n",
    "for day in range(0, 366):\n",
    "    # Get the indices of the dates that match the current day of the year for day and night\n",
    "    indices_d = np.where(day_of_year_d == day+1)    # Add 1 to day because day_of_year starts from 1\n",
    "    indices_n = np.where(day_of_year_d == day+1)\n",
    "    \n",
    "    # Calculate the average temperature for the current day of the year for day and night, ignoring absent days\n",
    "    mean_temp_d = np.nanmean(abs_dataset_d[indices_d], axis=0) if indices_d[0].size > 0 else np.nan\n",
    "    mean_temp_n = np.nanmean(abs_dataset_n[indices_n], axis=0) if indices_n[0].size > 0 else np.nan\n",
    "        \n",
    "    # Assign the mean temperatures to the baseline arrays\n",
    "    abs_baseline_d[day] = mean_temp_d\n",
    "    abs_baseline_n[day] = mean_temp_n\n",
    "\n",
    "\n",
    "# Create a meshgrid for the x and y coordinates, to be used in the interpolation\n",
    "x = np.arange(256)\n",
    "y = np.arange(256)\n",
    "xx, yy = np.meshgrid(x, y)  # Grid of x, y coordinates\n",
    "\n",
    "\n",
    "# For all NaN values still present in the ocean, interpolate spatially\n",
    "for day in range(366):\n",
    "    for baseline_array in [abs_baseline_d, abs_baseline_n]:\n",
    "        # Get the current baseline and create a mask for the valid values\n",
    "        data = baseline_array[day]\n",
    "        valid_mask = ~np.isnan(data) #& italy_mask\n",
    "\n",
    "        # Get the valid values and their coordinates\n",
    "        values = data[valid_mask]\n",
    "        coords = np.array((xx[valid_mask], yy[valid_mask])).T   # Coordinates of the non-nan values, transposed back in 2D\n",
    "\n",
    "        # Perform the interpolation only on the ocean pixels (italy_mask)\n",
    "        data_interp = griddata(coords, values, (xx[italy_mask], yy[italy_mask]), method='linear')\n",
    "        # Assign the interpolated data back to the ocean pixels in the baseline array\n",
    "        baseline_array[day, italy_mask] = data_interp\n",
    "\n",
    "        # Perform a nearest-neighbor interpolation to fill in any remaining NaN values\n",
    "        valid_mask = ~np.isnan(baseline_array[day]) #& italy_mask\n",
    "        values = baseline_array[day, valid_mask]\n",
    "        coords = np.array((xx[valid_mask], yy[valid_mask])).T\n",
    "        interpolator = NearestNDInterpolator(coords, values)    # Nearest-neighbor interpolator\n",
    "        baseline_array[day, italy_mask] = interpolator((xx[italy_mask], yy[italy_mask]))    # Interpolation and assignment\n",
    "\n",
    "\n",
    "# Put the value 0 in the land pixels of the baseline arrays\n",
    "abs_baseline_d[:, ~italy_mask] = 0\n",
    "abs_baseline_n[:, ~italy_mask] = 0\n",
    "\n",
    "print(abs_baseline_d.shape)\n",
    "print(abs_baseline_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of the ABS baseline for a few days of the year\n",
    "\n",
    "# Create a dictionary to map the day numbers to the full names of the days and months. Used only for visualization purposes. 2020 is a leap year so we also get the 366th day\n",
    "day_names = {i: (datetime.datetime(2020, 1, 1) + datetime.timedelta(days=i-1)).strftime('%d %B') for i in range(1, 367)}\n",
    "\n",
    "# Define the days to plot\n",
    "days_to_plot = [1, 60, 199, 366]  # 1st of January, 29th of February, 17th of July, 31st of December\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(15, 20))  # Create a 4x2 grid of subplots\n",
    "\n",
    "# For each day to plot\n",
    "for i, day in enumerate(days_to_plot):\n",
    "    # Plot the day baseline for the day\n",
    "    im_d = axs[i, 0].imshow(abs_baseline_d[day-1], cmap='viridis')  # Subtract 1 from day because jan 1 is index 0 in the baseline array\n",
    "    axs[i, 0].set_title(f'Day {day_names[day]}')\n",
    "    fig.colorbar(im_d, ax=axs[i, 0])\n",
    "    \n",
    "    # Plot the night baseline for the day\n",
    "    im_n = axs[i, 1].imshow(abs_baseline_n[day-1], cmap='viridis')  # Subtract 1 from day because jan 1 is index 0 in the baseline array\n",
    "    axs[i, 1].set_title(f'Night {day_names[day]}')\n",
    "    fig.colorbar(im_n, ax=axs[i, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG : Iterate over the baseline arrays and check if there are still NaN values\n",
    "# for i, baseline_array in enumerate([abs_baseline_d, abs_baseline_n]):\n",
    "#     for day in range(baseline_array.shape[0]):\n",
    "#         if np.isnan(baseline_array[day]).any():\n",
    "#             print(f'NaN value found in baseline_array {i} on day {day}')\n",
    "#             plt.imshow(baseline_array[day])\n",
    "#             plt.colorbar()\n",
    "#             plt.title(f'Baseline_array {i} on day {day}')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DATASETS\n",
    "\n",
    "# np.save('dati/mist/datasets/dataset.npy', dataset)\n",
    "# np.save('dati/mist/datasets/date.npy', date)\n",
    "# np.save('dati/mist/datasets/baseline.npy', baseline)\n",
    "\n",
    "np.save('dati/mist/datasets/date_d.npy', date_d)\n",
    "np.save('dati/mist/datasets/date_n.npy', date_n)\n",
    "\n",
    "np.save('dati/mist/datasets/dataset_d.npy', dataset_d)\n",
    "np.save('dati/mist/datasets/dataset_n.npy', dataset_n)\n",
    "np.save('dati/mist/datasets/abs_dataset_d.npy', abs_dataset_d)\n",
    "np.save('dati/mist/datasets/abs_dataset_n.npy', abs_dataset_n)\n",
    "\n",
    "np.save('dati/mist/datasets/baseline_d.npy', baseline_d)\n",
    "np.save('dati/mist/datasets/baseline_n.npy', baseline_n)\n",
    "np.save('dati/mist/datasets/abs_baseline_d.npy', abs_baseline_d)\n",
    "np.save('dati/mist/datasets/abs_baseline_n.npy', abs_baseline_n)\n",
    "\n",
    "np.save('dati/mist/datasets/italy_mask.npy', italy_mask)\n",
    "np.save('dati/mist/datasets/data_min.npy', data_min)\n",
    "np.save('dati/mist/datasets/data_max.npy', data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASETS\n",
    "\n",
    "# dataset = np.load('dati/mist/datasets/dataset.npy')\n",
    "# date = np.load('dati/mist/datasets/date.npy')\n",
    "# baseline = np.load('dati/mist/datasets/baseline.npy')\n",
    "\n",
    "date_d = np.load('dati/mist/datasets/date_d.npy')\n",
    "date_n = np.load('dati/mist/datasets/date_n.npy')\n",
    "\n",
    "dataset_d = np.load('dati/mist/datasets/dataset_d.npy')\n",
    "dataset_n = np.load('dati/mist/datasets/dataset_n.npy')\n",
    "abs_dataset_d = np.load('dati/mist/datasets/abs_dataset_d.npy')\n",
    "abs_dataset_n = np.load('dati/mist/datasets/abs_dataset_n.npy')\n",
    "\n",
    "baseline_d = np.load('dati/mist/datasets/baseline_d.npy')\n",
    "baseline_n = np.load('dati/mist/datasets/baseline_n.npy')\n",
    "abs_baseline_d = np.load('dati/mist/datasets/abs_baseline_d.npy')\n",
    "abs_baseline_n = np.load('dati/mist/datasets/abs_baseline_n.npy')\n",
    "\n",
    "italy_mask = np.load('dati/mist/datasets/italy_mask.npy')\n",
    "data_min = np.load('dati/mist/datasets/data_min.npy')\n",
    "data_max = np.load('dati/mist/datasets/data_max.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for mediterrean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "files_y2002_2004c = glob.glob('dati/y2002_2004c/*.nc')\n",
    "files_y2005_2009c = glob.glob('dati/y2005_2009c/*.nc')\n",
    "files_y2010_2014c = glob.glob('dati/y2010_2014c/*.nc')\n",
    "files_y2015_2019c = glob.glob('dati/y2015_2019c/*.nc')\n",
    "files_y2020_2023c = glob.glob('dati/y2020_2023c/*.nc')\n",
    "all_files = files_y2002_2004c + files_y2005_2009c + files_y2010_2014c + files_y2015_2019c + files_y2020_2023c\n",
    "\n",
    "\n",
    "# Datasets and dates lists, for day and night\n",
    "dataset_d = []; date_d = []\n",
    "dataset_n = []; date_n = []\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    # Check if the dataset is day or night by checking the variable name: 'sst' for day, 'sst4' for night\n",
    "    if 'sst' in ds:\n",
    "        data = ds['sst'].values\n",
    "        data = np.where(ocean_mask, data, np.nan)    # Cut away measurements of lakes and rivers\n",
    "        # Extract the date from the product name. Example: AQUA_MODIS.20030722.L3m.DAY.SST.x_sst.nc\n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()    # Use the date in the file name for day data\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "\n",
    "        # Append the data and the date to the respective lists\n",
    "        dataset_d.append(data)\n",
    "        date_d.append(date)\n",
    "        \n",
    "    else:\n",
    "        data = ds['sst4'].values\n",
    "        data = np.where(ocean_mask, data, np.nan)\n",
    "        \n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "        \n",
    "        dataset_n.append(data)\n",
    "        date_n.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dataset_d = np.array(dataset_d)\n",
    "date_d = np.array(date_d)\n",
    "dataset_n = np.array(dataset_n)\n",
    "date_n = np.array(date_n)\n",
    "\n",
    "print(dataset_d.shape)\n",
    "print(date_d.shape)\n",
    "print(dataset_n.shape)\n",
    "print(date_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dati/mist/datasets/abs_mediterrean_d.npy', dataset_d)\n",
    "np.save('dati/mist/datasets/abs_mediterrean_n.npy', dataset_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for tirreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the area of interest, containing 4.5625 to 9.5∘ E and 39.5 to 44.4375∘ N\n",
    "med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "tirreno_coords = (4.5625, 9.5, 39.5, 44.4375)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "# cut landmask\n",
    "tirreno_mask = tmask[\"tmask\"].sel(lon=slice(4.5625, 9.5), lat=slice(39.5, 44.4375))\n",
    "tirreno_mask = np.flipud(tirreno_mask)  #flip the mask\n",
    "print(tirreno_mask.shape)   #119x119, despite the documentation saying 112x112\n",
    "plt.imshow(tirreno_mask)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(lat, lon, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res):\n",
    "    \"\"\"\n",
    "    Find the indices in the tmask array corresponding to the given latitude and longitude.\n",
    "\n",
    "    Returns:\n",
    "    (int, int): Indices corresponding to the given latitude and longitude.\n",
    "    \"\"\"\n",
    "    lat_index = int((lat - lat_min) / lat_res)\n",
    "    lon_index = int((lon - lon_min) / lon_res)\n",
    "    return lat_index, lon_index\n",
    "\n",
    "\n",
    "lat_min = 30  # Minimum latitude\n",
    "lat_max = 46  # Maximum latitude\n",
    "lon_min = -5  # Minimum longitude\n",
    "lon_max = 36  # Maximum longitude\n",
    "lat_res = (lat_max - lat_min) / 384  # Latitude resolution\n",
    "lon_res = (lon_max - lon_min) / 984  # Longitude resolution\n",
    "\n",
    "# Coordinates of the point of interest\n",
    "lat1 = 44.4375\n",
    "lon1 = 4.5625\n",
    "\n",
    "lat2 = 39.5\n",
    "lon2 = 9.5\n",
    "\n",
    "# Find the indices\n",
    "lat_index1, lon_index1 = find_indices(lat1, lon1, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "print(f\"Indices for coordinates ({lat1}, {lon1}): ({lat_index1}, {lon_index1})\")\n",
    "lat_index2, lon_index2 = find_indices(lat2, lon2, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "print(f\"Indices for coordinates ({lat2}, {lon2}): ({lat_index2}, {lon_index2})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeling extra! All four corners of the tirreno area\n",
    "def find_coordinates(lat_index, lon_index, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res):\n",
    "    \"\"\"\n",
    "    Find the latitude and longitude corresponding to the given indices in the tmask array.\n",
    "\n",
    "    Returns:\n",
    "    (float, float): Latitude and longitude corresponding to the given indices.\n",
    "    \"\"\"\n",
    "    lat = lat_min + lat_index * lat_res\n",
    "    lon = lon_min + lon_index * lon_res\n",
    "    return lat, lon\n",
    "\n",
    "# Given indices range\n",
    "lat_min_index = 90\n",
    "lat_max_index = 346\n",
    "lon_min_index = 229\n",
    "lon_max_index = 485\n",
    "\n",
    "# Latitude and longitude ranges of mediterrean area\n",
    "lat_min = 30\n",
    "lat_max = 46\n",
    "lon_min = -5\n",
    "lon_max = 36\n",
    "\n",
    "# Calculate resolution\n",
    "lat_res = (lat_max - lat_min) / 384\n",
    "lon_res = (lon_max - lon_min) / 984\n",
    "\n",
    "# Find coordinates for the four corners\n",
    "top_left = find_coordinates(lat_min_index, lon_min_index, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "top_right = find_coordinates(lat_min_index, lon_max_index, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "bottom_left = find_coordinates(lat_max_index, lon_min_index, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "bottom_right = find_coordinates(lat_max_index, lon_max_index, lat_min, lat_max, lon_min, lon_max, lat_res, lon_res)\n",
    "\n",
    "print(f\"Top-left corner coordinates: {top_left}\")\n",
    "print(f\"Top-right corner coordinates: {top_right}\")\n",
    "print(f\"Bottom-left corner coordinates: {bottom_left}\")\n",
    "print(f\"Bottom-right corner coordinates: {bottom_right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(346-256, 346)\n",
    "print(229, 229+256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(384-346, 38 + 256)\n",
    "print(348 - 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_mask = tmask[\"tmask\"].values[90:346, 229:485]  # Extract the sst data (flipped correctly)\n",
    "tirreno_mask = np.flipud(ocean_mask)\n",
    "print(tirreno_mask.shape)\n",
    "plt.imshow(tirreno_mask)\n",
    "plt.show()\n",
    "np.save('dati/mist/datasets/tirreno_mask.npy', tirreno_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "files_y2002_2004c = glob.glob('dati/y2002_2004c/*.nc')\n",
    "files_y2005_2009c = glob.glob('dati/y2005_2009c/*.nc')\n",
    "files_y2010_2014c = glob.glob('dati/y2010_2014c/*.nc')\n",
    "files_y2015_2019c = glob.glob('dati/y2015_2019c/*.nc')\n",
    "files_y2020_2023c = glob.glob('dati/y2020_2023c/*.nc')\n",
    "all_files = files_y2002_2004c + files_y2005_2009c + files_y2010_2014c + files_y2015_2019c + files_y2020_2023c\n",
    "\n",
    "\n",
    "# Datasets and dates lists, for day and night\n",
    "dataset_d = []; date_d = []\n",
    "dataset_n = []; date_n = []\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    # Check if the dataset is day or night by checking the variable name: 'sst' for day, 'sst4' for night\n",
    "    if 'sst' in ds:\n",
    "        data = ds['sst'].values[38:294, 229:485]\n",
    "        data = np.where(tirreno_mask, data, np.nan)    # Cut away measurements of lakes and rivers\n",
    "        # Extract the date from the product name. Example: AQUA_MODIS.20030722.L3m.DAY.SST.x_sst.nc\n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()    # Use the date in the file name for day data\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "\n",
    "        # Append the data and the date to the respective lists\n",
    "        dataset_d.append(data)\n",
    "        date_d.append(date)\n",
    "        \n",
    "    else:\n",
    "        data = ds['sst4'].values[38:294, 229:485]\n",
    "        data = np.where(tirreno_mask, data, np.nan)\n",
    "        \n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "        date = np.array(date, dtype='datetime64[D]')\n",
    "        date = date.astype(int)\n",
    "        \n",
    "        dataset_n.append(data)\n",
    "        date_n.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dataset_d = np.array(dataset_d)\n",
    "date_d = np.array(date_d)\n",
    "dataset_n = np.array(dataset_n)\n",
    "date_n = np.array(date_n)\n",
    "\n",
    "print(dataset_d.shape)\n",
    "print(date_d.shape)\n",
    "print(dataset_n.shape)\n",
    "print(date_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dati/mist/datasets/abs_tirreno_d.npy', dataset_d)\n",
    "np.save('dati/mist/datasets/abs_tirreno_n.npy', dataset_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_tirreno_d = np.load('dati/mist/datasets/abs_tirreno_d.npy')\n",
    "abs_tirreno_n = np.load('dati/mist/datasets/abs_tirreno_n.npy')\n",
    "tirreno_mask = np.load('dati/mist/datasets/tirreno_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the first day of the tirreno dataset, with overlayed mask\n",
    "day = 27\n",
    "plt.imshow(abs_tirreno_n[day])\n",
    "plt.imshow(tirreno_mask, alpha=0.25)\n",
    "plt.show()\n",
    "plt.imshow(tirreno_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map with traced areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ocean_mask\n",
    "plt.figure(figsize=(12, 6))  # Increase the figure size (width, height)\n",
    "plt.imshow(ocean_mask)\n",
    "plt.axis('off')  # Remove the frame\n",
    "\n",
    "# Create a red rectangle patch for the first area\n",
    "rect1 = patches.Rectangle((310, 0), 256, 256, linewidth=1, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect1)\n",
    "\n",
    "# # Create a magenta rectangle patch for the second area\n",
    "# rect2 = patches.Rectangle((229, 38), 256, 256, linewidth=1, edgecolor='green', facecolor='none')\n",
    "# plt.gca().add_patch(rect2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the image screenshotMed.png\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('screenshotMed.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')  # Remove the frame\n",
    "plt.show()\n",
    "\n",
    "print(img.shape)    #print information about the image\n",
    "print(img.shape[0]/img.shape[1])    #print the proportions of the shape of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "# Load and resize the image\n",
    "img = Image.open('screenshotMed.png')\n",
    "img_resized = img.resize((984, 384))\n",
    "# Convert the resized image to an array\n",
    "img_resized_array = np.array(img_resized)\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 6))  # Increase the figure size (width, height)\n",
    "\n",
    "# Plot the resized image\n",
    "plt.imshow(img_resized_array)\n",
    "plt.axis('off')  # Remove the frame\n",
    "\n",
    "# Create a red rectangle patch for the first area\n",
    "rect1 = patches.Rectangle((310, 0), 256, 256, linewidth=1, edgecolor='red', facecolor='none')\n",
    "plt.gca().add_patch(rect1)\n",
    "\n",
    "# # Create a green rectangle patch for the second area\n",
    "# rect2 = patches.Rectangle((229, 38), 256, 256, linewidth=1, edgecolor='green', facecolor='none')\n",
    "# plt.gca().add_patch(rect2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
