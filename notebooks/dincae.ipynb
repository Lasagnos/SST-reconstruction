{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_sst_revlat = xr.open_dataset('dati/mist/old/dincae/modis_sst_revlat.nc')\n",
    "modis_sst_revlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_sst_revlat_add_clouds = xr.open_dataset('dati/mist/old/dincae/modis_sst_revlat_add_clouds.nc')\n",
    "modis_sst_revlat_add_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_sst = modis_sst_revlat['sst']\n",
    "print('shape of sst data:', msr_sst.shape)\n",
    "\n",
    "msr_qual = modis_sst_revlat['qual']\n",
    "print('shape of qual data:', msr_qual.shape)\n",
    "\n",
    "msr_sst_t = modis_sst_revlat['sst_t']\n",
    "print('shape of sst_t data:', msr_sst_t.shape)\n",
    "\n",
    "msr_mask = modis_sst_revlat['mask']\n",
    "print('shape of sst mask:', msr_mask.shape)\n",
    "\n",
    "msr_count_nomissing = modis_sst_revlat['count_nomissing']\n",
    "print('shape of count_nomissing data:', msr_count_nomissing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msrc_sst = modis_sst_revlat_add_clouds['sst']\n",
    "print('shape of sst data:', msrc_sst.shape)\n",
    "\n",
    "msrc_qual = modis_sst_revlat_add_clouds['qual']\n",
    "print('shape of qual data:', msrc_qual.shape)\n",
    "\n",
    "msrc_sst_t = modis_sst_revlat_add_clouds['sst_t']\n",
    "print('shape of sst_t data:', msrc_sst_t.shape)\n",
    "\n",
    "msrc_mask = modis_sst_revlat_add_clouds['mask']\n",
    "print('shape of sst mask:', msrc_mask.shape)\n",
    "\n",
    "msrc_time_index_validation = modis_sst_revlat_add_clouds['time_index_validation']\n",
    "print('shape of time_index_validation data:', msrc_time_index_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count quality levels over both datasets\n",
    "\n",
    "# msr_qual = msr_qual.values\n",
    "# msrc_qual = msrc_qual.values\n",
    "# print(msr_qual.shape)\n",
    "# print(msrc_qual.shape)\n",
    "\n",
    "def analyze_quality(qual_array):\n",
    "    # Flatten the array to make counting easier\n",
    "    flattened = qual_array.flatten()\n",
    "    \n",
    "    # Count the total number of valid (non-NaN) datapoints\n",
    "    total_valid = np.count_nonzero(~np.isnan(flattened))\n",
    "    \n",
    "    # Initialize a dictionary to hold counts and percentiles for each quality level\n",
    "    quality_counts = {i: np.count_nonzero(flattened == i) for i in range(6)}\n",
    "    quality_percentiles = {i: (quality_counts[i] / total_valid) * 100 for i in range(6)}\n",
    "    \n",
    "    return quality_counts, quality_percentiles\n",
    "\n",
    "# Analyze quality for msr and msrc\n",
    "msr_quality_counts, msr_quality_percentiles = analyze_quality(msr_qual)\n",
    "msrc_quality_counts, msrc_quality_percentiles = analyze_quality(msrc_qual)\n",
    "\n",
    "# Print the results\n",
    "\n",
    "# Print the results\n",
    "print(\"Quality counts for MSR:\", msr_quality_counts)\n",
    "print(\"Quality percentiles for MSR:\", msr_quality_percentiles)\n",
    "print(\"Quality counts for MSRC:\", msrc_quality_counts)\n",
    "print(\"Quality percentiles for MSRC:\", msrc_quality_percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToPlot = 3235\n",
    "# index1: 3235\n",
    "# index2: 3236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_sst_t[indexToPlot].plot()\n",
    "#msrc_sst_t[indexToPlot].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot msr dataset\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title('sst')\n",
    "plt.imshow(msr_sst[indexToPlot, :, :], cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title('qual')\n",
    "plt.imshow(msr_qual[indexToPlot, :, :], cmap='tab20b', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title('sst_t')\n",
    "plt.imshow(msr_sst_t[indexToPlot, :, :], cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title('mask')\n",
    "plt.imshow(msr_mask, cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title('count_nomissing')\n",
    "plt.imshow(msr_count_nomissing, cmap='YlOrBr', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot msrc dataset\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('sst')\n",
    "plt.imshow(msrc_sst[indexToPlot, :, :], cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('qual')\n",
    "plt.imshow(msrc_qual[indexToPlot, :, :], cmap='tab20b', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('sst_t')\n",
    "plt.imshow(msrc_sst_t[indexToPlot, :, :], cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('mask')\n",
    "plt.imshow(msrc_mask, cmap='viridis', origin='lower')\n",
    "plt.colorbar()\n",
    "\n",
    "# plt.subplot(2, 3, 5)\n",
    "# plt.title('time_index_validation')\n",
    "# msrc_time_index_validation.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#properly plot time_index_validation\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title('time_index_validation')\n",
    "msrc_time_index_validation.plot()\n",
    "plt.show()\n",
    "\n",
    "# sorted_time_index_validation = np.sort(msrc_time_index_validation.values)\n",
    "# print('time_index_validation:', sorted_time_index_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the masks and sst in the two datasets (msr and msrc) are the same\n",
    "\n",
    "for index in range(msr_sst.shape[0]):\n",
    "    mask1 = np.isnan(msr_sst[index, :, :])\n",
    "    mask2 = np.isnan(msrc_sst[index, :, :])\n",
    "\n",
    "    temp = (mask1 == mask2)\n",
    "    if not np.all(temp):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('sst of msr')\n",
    "        plt.imshow(mask1, cmap='viridis', origin='lower')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('sst of msrc')\n",
    "        plt.imshow(mask2, cmap='viridis', origin='lower')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('diff')\n",
    "        mask_diff = np.logical_xor(mask1, mask2)\n",
    "        plt.imshow(mask_diff, cmap='viridis', origin='lower')\n",
    "        plt.show()\n",
    "\n",
    "    temp = (np.where(~mask1, msr_sst[index, :, :] == msrc_sst[index, :, :], True))\n",
    "    if not np.all(temp):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('sst of msr')\n",
    "        plt.imshow(msr_sst[index, :, :], cmap='viridis', origin='lower')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('sst of msrc')\n",
    "        plt.imshow(msrc_sst[index, :, :], cmap='viridis', origin='lower')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('diff')\n",
    "        sst_diff = np.where(~mask1, np.abs(msr_sst[index, :, :] - msrc_sst[index, :, :]), np.nan)\n",
    "        #print min and max of difference\n",
    "        print('min of diff:', np.nanmin(sst_diff))\n",
    "        print('max of diff:', np.nanmax(sst_diff))\n",
    "        plt.imshow(sst_diff, cmap='viridis', origin='lower')\n",
    "        plt.colorbar\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msr_sst = msr_sst.values\n",
    "msr_sst_t_array = msr_sst_t.values\n",
    "msrc_sst_t_array = msrc_sst_t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove index 3235 and 3236 from the dataset\n",
    "msr_sst = np.delete(msr_sst, [3235, 3236], axis=0)\n",
    "msr_sst_t = np.delete(msr_sst_t, [3235, 3236], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the clouds in sst_t are always greater than the clouds in sst\n",
    "\n",
    "for index in range(msr_sst.shape[0]):\n",
    "\n",
    "    # MSR - Check if the clouds in sst_t are always greater than the clouds in sst\n",
    "    mask1 = np.isnan(msr_sst[index, :, :])\n",
    "    mask2 = np.isnan(msr_sst_t[index, :, :])\n",
    "    temp = np.logical_or(~mask1, mask2) # if sst is masked, sst_t is also masked (sst_t masks more)     Vero anche se invertito: SST=SST_T per quanto riguarda i NaN\n",
    "    if not np.all(temp):\n",
    "        print('msr index:', index)  \n",
    "\n",
    "#     # MSRC - Check if the clouds in sst_t are always greater than the clouds in sst\n",
    "#     mask3 = np.isnan(msrc_sst[index, :, :])\n",
    "#     mask4 = np.isnan(msrc_sst_t[index, :, :])\n",
    "#     temp = np.logical_or(~mask3, mask4)\n",
    "#     if not np.all(temp):\n",
    "#         print('msrc index:', index)\n",
    "    \n",
    "#     # Check if the clouds in MSRC_sst_t are always greater than the clouds in MSR_sst_t\n",
    "#     temp = np.logical_or(~mask2, mask4)\n",
    "#     if not np.all(temp):\n",
    "#         print('msr sst_t index:', index)\n",
    "#     # Check if the clouds in MSR_sst_t are always greater than the clouds in MSRC_sst_t\n",
    "#     temp = np.logical_or(~mask4, mask2)\n",
    "#     if not np.all(temp):\n",
    "#         print('msrc sst_t index:', index)   #FALSE!\n",
    "\n",
    "# # Conclusion: MSRC_SST_T is the most clouded. the normal stt are the same in both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "dincae_coords = (12, 19, 40, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "raw_coords = (310, 566, 0, 256)  # (x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot of a specific day for our data and dincae data\n",
    "\n",
    "d_index = 22\n",
    "msr_time = modis_sst_revlat['time']\n",
    "print(msr_time[d_index].values)\n",
    "\n",
    "ds = xr.open_dataset('dati/y2002_2004c/AQUA_MODIS.20030123.L3m.DAY.SST4.x_sst4.nc')    # Open the dataset\n",
    "print(ds.attrs['time_coverage_end'])\n",
    "\n",
    "data1 = ds['sst4']   # Extract the sst variables\n",
    "data1 = data1.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "data2 = modis_sst_revlat['sst']\n",
    "\n",
    "print(data1.shape, data2.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(data2[d_index], origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lat and lon from our dataset, and raw coordinates from dincae data\n",
    "\n",
    "example_ds = xr.open_dataset('dati/y2002_2004c/AQUA_MODIS.20030122.L3m.DAY.SST.x_sst.nc')    # Open the dataset\n",
    "print(example_ds['sst'].shape)\n",
    "\n",
    "# Calculate the resolution\n",
    "lon_res = (med_coords[1] - med_coords[0]) / example_ds['sst'].shape[1]\n",
    "lat_res = (med_coords[3] - med_coords[2]) / example_ds['sst'].shape[0]\n",
    "\n",
    "# Convert the raw coordinates of our data ([0:256, 310:566]) to longitude and latitude\n",
    "lon_min = med_coords[0] + raw_coords[0] * lon_res\n",
    "lon_max = med_coords[0] + raw_coords[1] * lon_res\n",
    "lat_min = med_coords[3] - raw_coords[3] * lat_res\n",
    "lat_max = med_coords[3] - raw_coords[2] * lat_res\n",
    "\n",
    "lonlat_coords = (lon_min, lon_max, lat_min, lat_max)    # (lon_min, lon_max, lat_min, lat_max)\n",
    "print('lon/lat coords of italy square:', lonlat_coords)\n",
    "\n",
    "# Convert the longitude and latitude of dincae data to raw coordinates\n",
    "x_min = int((dincae_coords[0] - med_coords[0]) / lon_res)\n",
    "x_max = int((dincae_coords[1] - med_coords[0]) / lon_res)\n",
    "y_min = int((med_coords[3] - dincae_coords[3]) / lat_res)\n",
    "y_max = int((med_coords[3] - dincae_coords[2]) / lat_res)\n",
    "\n",
    "coords_on_med = (x_min, x_max, y_min, y_max)    # [0:144, 408:576]\n",
    "print('xy coords for dincae on the mediterrean:', coords_on_med)\n",
    "coords_on_italy = (x_min-raw_coords[0], x_max-raw_coords[0], y_min-raw_coords[2], y_max-raw_coords[2])  # [0:144, 98:266]\n",
    "print('xy coords for dincae on italy:', coords_on_italy)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Cut dataset values using longitude and latitude\n",
    "data_slice = example_ds['sst'].sel(lon=slice(lonlat_coords[0], lonlat_coords[1]), lat=slice(lonlat_coords[3], lonlat_coords[2]))\n",
    "print(data_slice.shape)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Italy cut using lon/lat')\n",
    "plt.imshow(data_slice)\n",
    "\n",
    "# Cut dincae values from dataset using raw coordinates\n",
    "data_crop = example_ds['sst'].values[coords_on_med[2]:coords_on_med[3], coords_on_med[0]:coords_on_med[1]]\n",
    "print(data_crop.shape)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('dincae cut using raw coordinates from mediterrean')\n",
    "plt.imshow(data_crop)\n",
    "\n",
    "# Cut dincae values from italy square using raw coordinates\n",
    "data_crop_italy = example_ds['sst'].values[raw_coords[2]:raw_coords[3], raw_coords[0]:raw_coords[1]]\n",
    "data_crop_italy = data_crop_italy[coords_on_italy[2]:coords_on_italy[3], coords_on_italy[0]:coords_on_italy[1]]\n",
    "print(data_crop_italy.shape)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('dincae cut using raw coordinates from italy')\n",
    "plt.imshow(data_crop_italy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the lonlat coordinates to obtain italy_mask, check if it's the same as the one obtained with raw coordinates\n",
    "\n",
    "tmask = xr.open_dataset('dati/mist/tmask_interpolated.nc')\n",
    "\n",
    "ocean_mask = tmask['tmask']   # Extract the sst data\n",
    "ocean_mask = ocean_mask.sel(lat=slice(None, None, -1))   # Flip the latitude axis to match the data\n",
    "print('ocean mask shape:', ocean_mask.shape)\n",
    "# plt.imshow(ocean_mask)\n",
    "# plt.show()\n",
    "\n",
    "# Cut using raw coordinates\n",
    "italy_mask1 = ocean_mask[0:256, 310:566]    # Focus on italy, 0 for land, 1 for sea\n",
    "italy_mask1 = italy_mask1.astype(bool)\n",
    "print('italy mask\\'s shape cut with raw coordinates', italy_mask1.shape)\n",
    "# plt.imshow(italy_mask1)\n",
    "# plt.show()\n",
    "\n",
    "# Cut using lonlat coordinates\n",
    "italy_mask2 = ocean_mask.sel(lon=slice(lonlat_coords[0], lonlat_coords[1]), lat=slice(lonlat_coords[3], lonlat_coords[2]))\n",
    "italy_mask2 = italy_mask2.astype(bool)\n",
    "print('italy mask\\'s shape cut with lat and lon', italy_mask2.shape)\n",
    "# plt.imshow(italy_mask2)\n",
    "# plt.show()\n",
    "\n",
    "# Check if the two masks are the same\n",
    "temp = (italy_mask1 == italy_mask2)\n",
    "if np.all(temp):\n",
    "    print('The two masks are the same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dincae Italy mask \n",
    "\n",
    "# Get dincae italy mask and check if it has the same proportions as the real dincae mask\n",
    "dincae_italy_mask_m = ocean_mask.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "dincae_italy_mask_m = dincae_italy_mask_m.astype(bool)\n",
    "\n",
    "italy_mask = ocean_mask[0:256, 310:566]\n",
    "dincae_italy_mask_i = italy_mask[coords_on_italy[2]:coords_on_italy[3], coords_on_italy[0]:coords_on_italy[1]]  #[98:266, 0:144]\n",
    "dincae_italy_mask_i = dincae_italy_mask_i.astype(bool)\n",
    "\n",
    "print('msr mask shape:', msr_mask.shape, ', proportions:', msr_mask.shape[0]/msr_mask.shape[1])\n",
    "print('dincae italy mask shape:', dincae_italy_mask_m.shape, ', proportions:', dincae_italy_mask_m.shape[0]/dincae_italy_mask_m.shape[1])\n",
    "print('dincae italy mask shape:', dincae_italy_mask_i.shape, ', proportions:', dincae_italy_mask_i.shape[0]/dincae_italy_mask_i.shape[1], '(10 pixels on the side are cut off)')\n",
    "\n",
    "# cut italy_mask to select dincae coordinates\n",
    "subItalyMask = ocean_mask[y_min:y_max, x_min:x_max]\n",
    "subItalyMask = subItalyMask.astype(bool)\n",
    "\n",
    "#plt.imshow(dincae_italy_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare masks\n",
    "\n",
    "# Plot both masks\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Actual Dincae Italy mask')\n",
    "plt.imshow(msr_mask, origin='lower')    # CAREFUL! The actual mask is flipped\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Our Dincae Italy mask')\n",
    "plt.imshow(dincae_italy_mask_m)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Our Dincae Italy mask cut on italy_mask')\n",
    "plt.imshow(dincae_italy_mask_i)\n",
    "plt.show()\n",
    "\n",
    "# Calculate difference and plot it\n",
    "mask_diff = np.flipud(msr_mask) - dincae_italy_mask_m\n",
    "plt.imshow(mask_diff, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an appropriate dincae mask\n",
    "dincae_mask = dincae_italy_mask_m.copy()\n",
    "\n",
    "# Find the coordinates of the -1 value in mask_diff\n",
    "coords = np.argwhere(mask_diff.values == -1)\n",
    "\n",
    "# If there really are -1 values\n",
    "if coords.size:\n",
    "    for coord in coords:\n",
    "        x, y = coord    # Get the coordinates\n",
    "        dincae_mask[x, y] = 0 # Set the corresponding point in dincae_mask to 0\n",
    "\n",
    "# Plot final mask\n",
    "plt.imshow(dincae_mask, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "#Check difference with real dincae mask\n",
    "check_differences = np.flipud(msr_mask) - dincae_mask\n",
    "plt.imshow(check_differences, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Creation for 2003-2016 span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation (2003-2016)\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "files_y2002_2004c = glob.glob('dati/y2002_2004c/*.nc')\n",
    "files_y2005_2009c = glob.glob('dati/y2005_2009c/*.nc')\n",
    "files_y2010_2014c = glob.glob('dati/y2010_2014c/*.nc')\n",
    "files_y2015_2019c = glob.glob('dati/y2015_2019c/*.nc')\n",
    "#files_y2020_2023c = glob.glob('dati/y2020_2023c/*.nc')\n",
    "all_files = files_y2002_2004c + files_y2005_2009c + files_y2010_2014c + files_y2015_2019c #+ files_y2020_2023c\n",
    "\n",
    "\n",
    "# Datasets and dates lists, for day and night\n",
    "dincae_dataset = []; dincae_date = []\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.to_datetime('2003-01-01').date()\n",
    "end_date = pd.to_datetime('2016-12-31').date()\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "    # Check if the dataset is night by checking the variable name: 'sst4' for night\n",
    "    if 'sst4' in ds:\n",
    "        # Extract the date from the product_name attribute\n",
    "        date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "\n",
    "        # Check if the date is within the desired range\n",
    "        if start_date <= date <= end_date:\n",
    "            data = ds['sst4'].values[0:256, 310:566]\n",
    "            data = np.where(italy_mask, data, np.nan)    # Cut away measurements of lakes and rivers\n",
    "            \n",
    "            # Convert the date to an integer\n",
    "            date = np.array(date, dtype='datetime64[D]')\n",
    "            date = date.astype(int)\n",
    "            \n",
    "            dincae_dataset.append(data)\n",
    "            dincae_date.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dincae_dataset = np.array(dincae_dataset)\n",
    "dincae_date = np.array(dincae_date)\n",
    "\n",
    "print(dincae_dataset.shape)\n",
    "print(dincae_date.shape)\n",
    "print(dincae_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the msr datasets in numpy arrays\n",
    "msr_sst_t_array = modis_sst_revlat['sst_t'].values\n",
    "msrc_sst_t_array = modis_sst_revlat_add_clouds['sst_t'].values\n",
    "print(msr_sst_t_array.shape)\n",
    "print(msrc_sst_t_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing days in our dataset\n",
    "\n",
    "# Convert the dincae time stamps to int like the ones in our dataset\n",
    "dincae_time = modis_sst_revlat['time']\n",
    "#Consider only the date part, and convert dates to epoch time\n",
    "dincae_time = np.array(dincae_time.values, dtype='datetime64[D]')\n",
    "dincae_time = dincae_time.astype(int)\n",
    "print('time is now in the form of:', dincae_time)\n",
    "\n",
    "# #reconvert to datetime\n",
    "# dincae_time = np.array(dincae_time, dtype='datetime64[D]')\n",
    "# print(dincae_time)\n",
    "# # Check if the time stamps are the same\n",
    "# time_diff = msr_time.values - dincae_time\n",
    "# print('time_diff:', time_diff)\n",
    "\n",
    "# #Some values are missing in our dataset! Identify them and remove them from the msr arrays\n",
    "# missing_values = np.setdiff1d(dincae_time, dincae_date)\n",
    "# dates_missing_values = np.array(missing_values, dtype='datetime64[D]')\n",
    "# print('missing dates:', missing_values, ', aka', dates_missing_values)\n",
    "\n",
    "\n",
    "# #Remove the missing values from the msr arrays\n",
    "# mask = np.isin(dincae_time, dincae_date)    # Create a boolean mask and apply it to the msr arrays\n",
    "# msr_sst_array = msr_sst_array[mask]\n",
    "# msrc_sst_t_array = msrc_sst_t_array[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the date 15288 and 15289 in dincae_time\n",
    "index1 = np.where(dincae_time == 15288)[0][0]\n",
    "index2 = np.where(dincae_time == 15289)[0][0]\n",
    "print('index1:', index1)\n",
    "print('index2:', index2)\n",
    "\n",
    "# plot the msr sst and msrc sst_t for these 2 dates\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('msr sst')\n",
    "plt.imshow(msr_sst_array[index1], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('msrc sst_t')\n",
    "plt.imshow(msrc_sst_t_array[index1], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#print min and max of index1\n",
    "print('min of msr sst:', np.nanmin(msr_sst_array[index1]))\n",
    "print('max of msr sst:', np.nanmax(msr_sst_array[index1]))\n",
    "print('min of msrc sst_t:', np.nanmin(msrc_sst_t_array[index1]))\n",
    "print('max of msrc sst_t:', np.nanmax(msrc_sst_t_array[index1]))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('msr sst')\n",
    "plt.imshow(msr_sst_array[index2], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('msrc sst_t')\n",
    "plt.imshow(msrc_sst_t_array[index2], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#print min and max of index2\n",
    "print('min of msr sst:', np.nanmin(msr_sst_array[index2]))\n",
    "print('max of msr sst:', np.nanmax(msr_sst_array[index2]))\n",
    "print('min of msrc sst_t:', np.nanmin(msrc_sst_t_array[index2]))\n",
    "print('max of msrc sst_t:', np.nanmax(msrc_sst_t_array[index2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the msr_sst_array in indexes [3235, 3236] so that they have nans in points where they have 45.000717 degrees\n",
    "\n",
    "indexes_to_change = [3235, 3236]\n",
    "for index in indexes_to_change:\n",
    "    msr_sst_array[index] = np.where(msr_sst_array[index] == 45.000717, np.nan, msr_sst_array[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find in msr_sst_array and msrc_sst_t_array the measurements that have at least one point at 45.000717 degrees, and plot them\n",
    "#find the indexes of the points that have at least one point at 45.000717 degrees\n",
    "indexes = []\n",
    "for i in range(len(msr_sst_array)):\n",
    "    if 45.000717 in msr_sst_array[i]:\n",
    "        indexes.append(i)\n",
    "print('indexes:', indexes)\n",
    "\n",
    "#plot the measurements that have at least one point at 45.000717 degrees\n",
    "for idx in indexes:\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'msr sst at index {idx}')\n",
    "    plt.imshow(msr_sst_array[idx], cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'msrc sst_t at index {idx}')\n",
    "    plt.imshow(msrc_sst_t_array[idx], cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the msr arrays have the same dates as our dataset\n",
    "print(msr_sst_t_array.shape)\n",
    "print(msrc_sst_t_array.shape)\n",
    "# print(dincae_dataset.shape)\n",
    "# print(dincae_date.shape)\n",
    "\n",
    "\n",
    "plt.imshow(msr_sst_t_array[22])\n",
    "plt.show()\n",
    "\n",
    "# Msr arrays are flipped, so flip vertically (flip on axis=1)\n",
    "msr_sst_t_array = np.flip(msr_sst_t_array, axis=1)\n",
    "msrc_sst_t_array = np.flip(msrc_sst_t_array, axis=1)\n",
    "\n",
    "plt.imshow(msr_sst_t_array[22])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute to cut off days with no added clouds in the dincae dataset\n",
    "\n",
    "same_mask_indices = []\n",
    "\n",
    "for i in range(msrc_sst_t_array.shape[0]):\n",
    "    cloud_mask = np.logical_not(np.isnan(msrc_sst_t_array[i]))\n",
    "    clear_mask = np.logical_not(np.isnan(msr_sst_array[i]))\n",
    "\n",
    "    # Check if the masks are the same\n",
    "    if np.all(cloud_mask == clear_mask):\n",
    "        same_mask_indices.append(i)\n",
    "    \n",
    "# Convert the list of indices to a numpy array\n",
    "same_mask_indices = np.array(same_mask_indices)\n",
    "# Create boolean arrays that are True for indices that should be kept\n",
    "keep_indices = np.ones(msrc_sst_t_array.shape[0], dtype=bool)\n",
    "keep_indices[same_mask_indices] = False\n",
    "\n",
    "msrc_sst_t_array = msrc_sst_t_array[keep_indices]\n",
    "msr_sst_array = msr_sst_array[keep_indices]\n",
    "\n",
    "print('shape of new msrc_sst_t_array:', msrc_sst_t_array.shape)\n",
    "print('shape of new msr_sst_array:', msr_sst_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE AND APPLY VALIDATION MASK\n",
    "\n",
    "tmask = xr.open_dataset('dati/mist/tmask_interpolated.nc')\n",
    "ocean_mask = tmask['tmask']   # Extract the sst data\n",
    "ocean_mask = ocean_mask.sel(lat=slice(None, None, -1))   # Flip the latitude axis to match the data\n",
    "\n",
    "ditalymask = ocean_mask.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "ditalymask = ditalymask.astype(bool)\n",
    "\n",
    "plt.imshow(ditalymask)\n",
    "plt.show()\n",
    "print('ditalymask shape:', ditalymask.shape)\n",
    "\n",
    "# plt.imshow(msr_sst_t_array[22])\n",
    "# plt.show()\n",
    "\n",
    "# for each measurement in msr_sst_array and msrc_sst_t_array, filter using ditalymask\n",
    "# if the measurement is not in the ocean, set it to nan\n",
    "for i in range(msr_sst_t_array.shape[0]):\n",
    "    msr_sst_t_array[i] = np.where(ditalymask, msr_sst_t_array[i], np.nan)\n",
    "    msrc_sst_t_array[i] = np.where(ditalymask, msrc_sst_t_array[i], np.nan)\n",
    "\n",
    "plt.imshow(msr_sst_t_array[22])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays to a file\n",
    "np.save('dati/mist/dincae/msr_sst_t_array.npy', msr_sst_t_array)\n",
    "np.save('dati/mist/dincae/msrc_sst_t_array.npy', msrc_sst_t_array)\n",
    "\n",
    "# np.save('dati/mist/dincae/dincae_dataset.npy', dincae_dataset)\n",
    "# np.save('dati/mist/dincae/dincae_date.npy', dincae_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confrontation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Conv2DTranspose, Concatenate, concatenate, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    real_mask = y_true[:,:,:,1:2]        # 0 for land/clouds, 1 for sea\n",
    "    y_true = y_true[:,:,:,0:1]          # The true SST values. Obfuscated areas are already converted to 0\n",
    "    \n",
    "    # Calculate the squared error only over clear sea\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    masked_error = squared_error * real_mask\n",
    "\n",
    "    # Calculate the mean of the masked errors\n",
    "    clear_loss = tf.reduce_mean(masked_error)     # The final loss\n",
    "\n",
    "    return clear_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClearMetric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    art_mask = y_true[:,:,:,2:3]   # 0 for land/clouds + artificials, 1 for clear, untouched sea\n",
    "    y_true = y_true[:,:,:,0:1]  # The true SST values. Obfuscated areas are already converted to 0\n",
    "\n",
    "    # Calculate the squared error only over clear sea\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    clear_masked_error = squared_error * art_mask\n",
    "    # Calculate the mean of the masked errors\n",
    "    clr_metric = tf.reduce_sum(clear_masked_error) / tf.reduce_sum(art_mask)\n",
    "\n",
    "    #loss = clear_loss\n",
    "    return clr_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArtificialMetric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)    # Was getting an error because of the different types: y_true in the metrics is float64 instead of the normal float32\n",
    "\n",
    "    real_mask = y_true[:,:,:,1:2]  # 0 for land/clouds, 1 for clear sea\n",
    "    art_mask = y_true[:,:,:,2:3]  # 0 for land/clouds + artificials, 1 for clear sea\n",
    "    added_mask = real_mask - art_mask  # 1 only for hidden sea, 0 for land/clouds and visible sea\n",
    "    y_true = y_true[:,:,:,0:1]  # The true SST values. Obfuscated areas are already converted to 0\n",
    "\n",
    "    # Calculate the squared error only over artificially clouded areas\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    artificial_masked_error = squared_error * added_mask\n",
    "    # Calculate the mean of the masked errors\n",
    "    art_metric = tf.reduce_sum(artificial_masked_error) / tf.reduce_sum(added_mask)\n",
    "\n",
    "    return art_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_shape = (256, 256, 4)\n",
    "lr = 1e-4\n",
    "loss = customLoss\n",
    "metrics = [ClearMetric, ArtificialMetric]\n",
    "\n",
    "italy_mask = np.load('dati/mist/datasets/italy_mask.npy')\n",
    "training_baseline_n = np.load('dati/mist/datasets/training_baseline_n.npy')\n",
    "\n",
    "dincae_date = np.arange(12053, 17167)   # 2003-01-01 to 2016-12-31\n",
    "\n",
    "msr_sst_array = np.load('dati/mist/dincae/msr_sst_array.npy')\n",
    "msrc_sst_t_array = np.load('dati/mist/dincae/msrc_sst_t_array.npy')\n",
    "\n",
    "data_min = np.nanmin(msr_sst_array, axis=(1, 2))\n",
    "data_max = np.nanmax(msr_sst_array, axis=(1, 2))\n",
    "data_min = np.nanmin(data_min)\n",
    "data_max = np.nanmax(data_max)\n",
    "print('data_min:', data_min, ', data_max:', data_max)\n",
    "\n",
    "norm_msr_sst_array = 2 * ((msr_sst_array - data_min) / (data_max - data_min)) - 1\n",
    "norm_msrc_sst_t_array = 2 * ((msrc_sst_t_array - data_min) / (data_max - data_min)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_y = 0    # 144 pixels tall\n",
    "offset_x = 98   # since x is 168 pixels wide but it has to stop at 256, 10 pixels are cut off from the right\n",
    "end_y = 144\n",
    "end_x = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dincae Generator\n",
    "# Dincae always uses the night dataset\n",
    "def dincae_generator(batch_size, msrData, msrcData, date):\n",
    "    i = 0   # Counter for the dataset. We will use the whole dataset, one batch at a time\n",
    "    while True:\n",
    "        batch_x = np.zeros((batch_size, 256, 256, 4))\n",
    "        batch_y = np.zeros((batch_size, 256, 256, 2))\n",
    "        batch_dates = np.empty(batch_size)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            # Get a day from msr dataset, and extract the corresponding mask from msrc dataset. Cut to the right size.\n",
    "            msr_image = np.nan_to_num(msrData[i], nan=0)\n",
    "            msr_image = msr_image[:end_y-offset_y, :end_x-offset_x]\n",
    "            msr_mask = np.isnan(msrData[i])\n",
    "            msr_mask = msr_mask[:end_y-offset_y, :end_x-offset_x]\n",
    "\n",
    "            msrc_mask = np.isnan(msrcData[i])\n",
    "            msrc_mask = msrc_mask[:end_y-offset_y, :end_x-offset_x]\n",
    "            \n",
    "            # Create a 256x256 image and masks, and insert them in the right place\n",
    "            greater_msr_image = np.zeros((256, 256), dtype=float)\n",
    "            greater_msr_image[offset_y:end_y, offset_x:end_x] = msr_image\n",
    "            greater_msr_mask = np.ones((256, 256), dtype=bool)\n",
    "            greater_msr_mask[offset_y:end_y, offset_x:end_x] = msr_mask\n",
    "            greater_msrc_mask = np.ones((256, 256), dtype=bool)\n",
    "            greater_msrc_mask[offset_y:end_y, offset_x:end_x] = msrc_mask\n",
    "            \n",
    "            # Apply the mask to the image\n",
    "            image_masked = np.where(greater_msrc_mask, 0, greater_msr_image)\n",
    "\n",
    "            # Extract the day-of-year from the date\n",
    "            date_series = pd.to_datetime(date[i], unit='D', origin=pd.Timestamp('1970-01-01'))\n",
    "            day_of_year = date_series.dayofyear\n",
    "\n",
    "            # Fix masks before they are used in the loss and metric functions\n",
    "            greater_msrc_mask = np.logical_not(greater_msrc_mask) # 1 for clear sea, 0 for land/clouds + artificials\n",
    "            greater_msr_mask = np.logical_not(greater_msr_mask) # 1 for clear sea, 0 for land/clouds\n",
    "\n",
    "            # Create batch_x and batch_y\n",
    "            batch_x[b, ..., 0] = image_masked                           #artificially cloudy image\n",
    "            batch_x[b, ..., 1] = greater_msrc_mask                      #artificial mask\n",
    "            batch_x[b, ..., 2] = italy_mask                             #land-sea mask\n",
    "            batch_x[b, ..., 3] = training_baseline_n[day_of_year - 1]   #baseline values for the current day (day_of_year starts from 1)\n",
    "\n",
    "            batch_y[b, ..., 0] = greater_msr_image                      #real image\n",
    "            batch_y[b, ..., 1] = greater_msr_mask                       #real mask\n",
    "\n",
    "            # Add the date information to the batch\n",
    "            batch_dates[b] = date[i]\n",
    "\n",
    "            # Increment the index\n",
    "            i += 1\n",
    "            if i >= msrData.shape[0]:\n",
    "                i = 0\n",
    "        \n",
    "        yield batch_x, batch_y, batch_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dincae_test_gen = dincae_generator(batch_size, dincae_dataset, dincae_date)\n",
    "dincae_test_gen = dincae_generator(batch_size, norm_msr_sst_array, norm_msrc_sst_t_array, dincae_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dincae generator\n",
    "\n",
    "x,y,dates = next(dincae_test_gen)\n",
    "r = np.random.randint(0, x.shape[0])    # Choose a random image from the batch\n",
    "\n",
    "maskdiff = y[r, :, :, 1] - x[r, :, :, 1]\n",
    "plt.imshow(maskdiff, cmap='viridis')\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot the y data\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(y[r, :, :, 0], cmap='viridis')\n",
    "plt.title(\"msr data)\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot the x data\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(x[r, :, :, 0], cmap='viridis')\n",
    "plt.title(\"covered msr / msrc data (model input)\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot the mask used as input\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(y[r, :, :, 1], cmap='viridis')\n",
    "plt.title(\"msr mask\")\n",
    "\n",
    "# Plot the baseline values\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(x[r, :, :, 1], cmap='viridis')\n",
    "plt.title(\"msrc mask (model input)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Information about the data\n",
    "print(\"are there nans?\", np.isnan(x).any())\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"min of all x:\", np.min(x[..., 0]))\n",
    "print(\"max of all x:\", np.max(x[..., 0]))\n",
    "print(\"min of this x:\", np.min(x[r, :, :, 0]))\n",
    "print(\"max of this x:\", np.max(x[r, :, :, 0]))\n",
    "\n",
    "date = pd.to_datetime(dates[r], unit='D', origin=pd.Timestamp('1970-01-01')).date()\n",
    "print(\"date of this image:\", date, \"(\", dates[r], \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# U-Net model with residual blocks\n",
    "\n",
    "def ResidualBlock(depth):\n",
    "    def apply(x):\n",
    "        input_depth = x.shape[3]    # Get the number of channels from the channels dimension\n",
    "        if input_depth == depth:    # It's already the desired channel number\n",
    "            residual = x\n",
    "        else:                       # Adjust the number of channels with a 1x1 convolution\n",
    "            residual = Conv2D(depth, kernel_size=1)(x)\n",
    "\n",
    "        x = BatchNormalization(center=False, scale=False)(x)    \n",
    "        x = Conv2D(depth, kernel_size=3, padding=\"same\", activation='swish')(x) \n",
    "        x = Conv2D(depth, kernel_size=3, padding=\"same\")(x)\n",
    "        x = Add()([x, residual])\n",
    "        return x\n",
    "    \n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownBlock(depth, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x\n",
    "        for _ in range(block_depth):\n",
    "            x = ResidualBlock(depth)(x)\n",
    "            skips.append(x)\n",
    "        x = AveragePooling2D(pool_size=2)(x)    #downsampling\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpBlock(depth, block_depth):\n",
    "    def apply(x):\n",
    "        x, skips = x\n",
    "        x = UpSampling2D(size=2, interpolation=\"bilinear\")(x)   #upsampling\n",
    "        for _ in range(block_depth):\n",
    "            x = Concatenate()([x, skips.pop()])\n",
    "            x = ResidualBlock(depth)(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def get_Unet(image_size, depths, block_depth):\n",
    "    input_images = Input(shape=image_size)  #input layer\n",
    "    \n",
    "    x = Conv2D(depths[0], kernel_size=1)(input_images)  #reduce the number of channels\n",
    "\n",
    "    skips = []  #store the skip connections\n",
    "    \n",
    "    for depth in depths[:-1]:   #downsampling layers\n",
    "        x = DownBlock(depth, block_depth)([x, skips])\n",
    "\n",
    "    for _ in range(block_depth):    #middle layer\n",
    "        x = ResidualBlock(depths[-1])(x)\n",
    "\n",
    "    for depth in reversed(depths[:-1]):   #upsampling layers\n",
    "        x = UpBlock(depth, block_depth)([x, skips])\n",
    "\n",
    "    x = Conv2D(1, kernel_size=1, kernel_initializer=\"zeros\", name = \"output_noise\")(x)  #output layer\n",
    "    \n",
    "    return Model(input_images, outputs=x, name=\"UNetInpainter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the model\n",
    "depths = [32, 64, 128]\n",
    "block_depth = 2\n",
    "model = get_Unet(input_shape, depths, block_depth)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Compile model with custom loss function\n",
    "opt = Adam(learning_rate=lr)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD WEIGHTS\n",
    "model.load_weights('weights/standard.h5')\n",
    "\n",
    "# WARNING: the 'baseline.h5' weight is trained on normalized data, but dincae uses the original data.\n",
    "# Need to train a new unet on the original data and use that weight\n",
    "# The use of absolute data may also be a problem for the generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE ERRORS\n",
    "print(\"Evaluating the errors, please wait...\")\n",
    "print(\"Ignore runtime errors, they are caused by 'nan slices' in the data\")\n",
    "\n",
    "# Initialize lists to store the errors and the maximum errors\n",
    "all_errors = []\n",
    "max_errors = []         #for each element\n",
    "clear_errors = []\n",
    "clear_max_errors = []   #for each element always visible\n",
    "hidden_errors = []\n",
    "hidden_max_errors = []  #for each element hidden artificially\n",
    "\n",
    "# Iterate over all the dataset\n",
    "for i in range(len(norm_msr_sst_array) // batch_size):\n",
    "    if i < len(norm_msr_sst_array) // batch_size:\n",
    "        x_true, y_true, dates = next(dincae_test_gen)\n",
    "    else:\n",
    "        # Special case for the last batch\n",
    "        remaining_size = len(norm_msr_sst_array) % batch_size\n",
    "        if remaining_size == 0:\n",
    "            break\n",
    "        x_true, y_true, dates = next(dincae_test_gen)\n",
    "        x_true = x_true[:remaining_size]\n",
    "        y_true = y_true[:remaining_size]\n",
    "        dates = dates[:remaining_size]\n",
    "\n",
    "    predictions = model.predict(x_true, verbose=0)  # Prediction\n",
    "\n",
    "    # Denormalize\n",
    "    predictions_adriatic = predictions[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "    msr_images_adriatic = y_true[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "    predictions_denorm = ((predictions_adriatic + 1) / 2) * (data_max - data_min) + data_min  # Denormalize the data\n",
    "    msr_images_denorm = ((msr_images_adriatic + 1) / 2) * (data_max - data_min) + data_min  # Denormalize the data\n",
    "\n",
    "    # Get the masks and calculate the errors\n",
    "    realMask = y_true[:, offset_y:end_y, offset_x:end_x, 1]     #real mask\n",
    "    hiddenMask = np.not_equal(y_true[:, offset_y:end_y, offset_x:end_x, 1], x_true[:, offset_y:end_y, offset_x:end_x, 1])   #hidden sea\n",
    "    clearMask = x_true[:, offset_y:end_y, offset_x:end_x, 1]                                  #clear sea\n",
    "\n",
    "\n",
    "    errors = np.where(realMask, np.abs(predictions_denorm - msr_images_denorm), np.nan)\n",
    "    clear_errors_batch = np.where(clearMask, np.abs(predictions_denorm - msr_images_denorm), np.nan)\n",
    "    hidden_errors_batch = np.where(hiddenMask, np.abs(predictions_denorm - msr_images_denorm), np.nan)\n",
    "\n",
    "    # Flatten the errors and add to the list\n",
    "    all_errors.extend(errors.flatten())\n",
    "    max_errors.append(np.nanmax(errors))\n",
    "    clear_errors.extend(clear_errors_batch.flatten())\n",
    "    clear_max_errors.append(np.nanmax(clear_errors_batch))\n",
    "    hidden_errors.extend(hidden_errors_batch.flatten())\n",
    "    hidden_max_errors.append(np.nanmax(hidden_errors_batch))\n",
    "\n",
    "# Convert to numpy array for easier calculations\n",
    "all_errors = np.array(all_errors)\n",
    "max_errors = np.array(max_errors)\n",
    "clear_errors = np.array(clear_errors)\n",
    "clear_max_errors = np.array(clear_max_errors)\n",
    "hidden_errors = np.array(hidden_errors)\n",
    "hidden_max_errors = np.array(hidden_max_errors)\n",
    "\n",
    "# Calculate the metrics over all errors\n",
    "avg_error = np.nanmean(all_errors)\n",
    "max_error = np.nanmax(all_errors)\n",
    "avg_max_error = np.nanmean(max_errors)\n",
    "var_error = np.nanvar(all_errors)\n",
    "rmse_error = np.sqrt(np.nanmean(all_errors**2))\n",
    "# Calculate the metrics over clear errors\n",
    "avg_clear_error = np.nanmean(clear_errors)\n",
    "max_clear_error = np.nanmax(clear_errors)\n",
    "avg_max_clear_error = np.nanmean(clear_max_errors)\n",
    "var_clear_error = np.nanvar(clear_errors)\n",
    "rmse_clear_error = np.sqrt(np.nanmean(clear_errors**2))\n",
    "# Calculate the metrics over hidden errors\n",
    "avg_hidden_error = np.nanmean(hidden_errors)\n",
    "max_hidden_error = np.nanmax(hidden_errors)\n",
    "avg_max_hidden_error = np.nanmean(hidden_max_errors)\n",
    "var_hidden_error = np.nanvar(hidden_errors)\n",
    "rmse_hidden_error = np.sqrt(np.nanmean(hidden_errors**2))\n",
    "\n",
    "# Print the metrics calculated over all elements\n",
    "print(f\"\\nAverage error over all elements:\", avg_error)\n",
    "print(f\"Average maximum error:\", avg_max_error, \", and maximum error:\", max_error)\n",
    "print(f\"Variance of errors over all elements:\", var_error)\n",
    "print(f\"RMSE over all elements:\", rmse_error)\n",
    "\n",
    "# Print the metrics calculated over clear elements\n",
    "print(f\"\\nAverage error over clear elements:\", avg_clear_error)\n",
    "print(f\"Average maximum error over clear elements:\", avg_max_clear_error, \", and maximum error over clear elements:\", max_clear_error)\n",
    "print(f\"Variance of errors over clear elements:\", var_clear_error)\n",
    "print(f\"RMSE over clear elements:\", rmse_clear_error)\n",
    "\n",
    "# Print the metrics calculated over hidden elements\n",
    "print(f\"\\nAverage error over hidden elements:\", avg_hidden_error)\n",
    "print(f\"Average maximum error over hidden elements:\", avg_max_hidden_error, \", and maximum error over hidden elements:\", max_hidden_error)\n",
    "print(f\"Variance of errors over hidden elements:\", var_hidden_error)\n",
    "print(f\"RMSE over hidden elements:\", rmse_hidden_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED TEST - identify high-error measurements\n",
    "\n",
    "# Initialize a list to store the dates, predictions, true values, and errors associated with high-error measurements\n",
    "high_error_dates = []\n",
    "high_error_predictions = []\n",
    "high_error_true_values = []\n",
    "high_error_data = []\n",
    "\n",
    "# Set the error threshold\n",
    "error_threshold = 10\n",
    "\n",
    "# Generate a batch\n",
    "for i in range(len(norm_msr_sst_array) // batch_size):\n",
    "    if i < len(norm_msr_sst_array) // batch_size:\n",
    "        x_true, y_true, dates = next(dincae_test_gen)\n",
    "    else:\n",
    "        # Special case for the last batch\n",
    "        remaining_size = len(norm_msr_sst_array) % batch_size\n",
    "        if remaining_size == 0:\n",
    "            break\n",
    "        x_true, y_true, dates = next(dincae_test_gen)\n",
    "        x_true = x_true[:remaining_size]\n",
    "        y_true = y_true[:remaining_size]\n",
    "        dates = dates[:remaining_size]\n",
    "\n",
    "    predictions = model.predict(x_true, verbose=0)  # Prediction\n",
    "\n",
    "    # Get the mask to select only the interested subsections\n",
    "    clear_masks = x_true[..., 1]                                            #unclouded\n",
    "    hidden_sea_masks = np.not_equal(y_true[..., 1], x_true[..., 1])         #hidden sea\n",
    "    clear_masks = clear_masks[:, offset_y:end_y, offset_x:end_x]\n",
    "    hidden_sea_masks = hidden_sea_masks[:, offset_y:end_y, offset_x:end_x]\n",
    "\n",
    "    # Evaluate the prediction compared to the msr image (compare only on the interested subsection)\n",
    "    predictions_adriatic = predictions[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "    predictions_denorm = np.where(hidden_sea_masks, ((predictions_adriatic + 1) / 2) * (data_max - data_min) + data_min, np.nan)\n",
    "    msr_images_adriatic = y_true[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "    msr_images_denorm = np.where(hidden_sea_masks, ((msr_images_adriatic + 1) / 2) * (data_max - data_min) + data_min, np.nan)\n",
    "\n",
    "    # Calculate the errors\n",
    "    h_errors = np.where(hidden_sea_masks, np.abs(predictions_denorm - msr_images_denorm), np.nan)\n",
    "\n",
    "\n",
    "    # Check each day in the batch\n",
    "    for j in range(h_errors.shape[0]):\n",
    "        # If the maximum error for this day is above the threshold, store the date, prediction, true value, and error\n",
    "        if np.nanmax(h_errors[j]) > error_threshold:\n",
    "            high_error_dates.append(dates[j])\n",
    "            high_error_predictions.append(predictions_denorm[j])\n",
    "            high_error_true_values.append(msr_images_denorm[j])\n",
    "            high_error_data.append(h_errors[j])\n",
    "            \n",
    "\n",
    "# Now, you can plot the images, predictions, errors, and dates of the high-error measurements\n",
    "for i in range(len(high_error_dates)):\n",
    "    print(f\"Date: {high_error_dates[i]}\")\n",
    "    max_error = np.nanmax(high_error_data[i])\n",
    "    print(f\"Max Error: {max_error}\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(high_error_true_values[i], cmap='hot', vmin=data_min, vmax=data_max)\n",
    "    plt.title('True Value')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(high_error_predictions[i], cmap='hot', vmin=data_min, vmax=data_max)\n",
    "    plt.title('Prediction')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(high_error_data[i], cmap='jet')\n",
    "    plt.title('Error')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REDO - Check for problematic spots in real images\n",
    "\n",
    "# Generate a batch\n",
    "x_true, y_true, dates = next(dincae_test_gen)\n",
    "# predictions = model.predict(x_true, verbose=0)  # Prediction\n",
    "\n",
    "# Denormalize\n",
    "# predictions_adriatic = predictions[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "# predictions_denorm = ((predictions_adriatic + 1) / 2) * (data_max - data_min) + data_min  # Denormalize the data\n",
    "msr_images_adriatic = y_true[:, offset_y:end_y, offset_x:end_x, 0]\n",
    "true_values_denorm = ((msr_images_adriatic + 1) / 2) * (data_max - data_min) + data_min  # Denormalize the data\n",
    "\n",
    "# Get the clear mask\n",
    "# clearMask = y_true[..., 1]  # 1 for all clear sea, 0 for land/clouds\n",
    "\n",
    "# Get the masks and calculate the errors\n",
    "realMask = y_true[:, offset_y:end_y, offset_x:end_x, 1]     #real mask\n",
    "hiddenMask = np.not_equal(y_true[:, offset_y:end_y, offset_x:end_x, 1], x_true[:, offset_y:end_y, offset_x:end_x, 1])   #hidden sea\n",
    "clearMask = x_true[:, offset_y:end_y, offset_x:end_x, 1]                                  #clear sea\n",
    "\n",
    "# # Initialize an array to store the differences\n",
    "# errors = np.where(realMask, np.abs(predictions_denorm - true_values_denorm), np.nan)\n",
    "# clear_errors_batch = np.where(clearMask, np.abs(predictions_denorm - true_values_denorm), np.nan)\n",
    "# hidden_errors_batch = np.where(hiddenMask, np.abs(predictions_denorm - true_values_denorm), np.nan)\n",
    "\n",
    "# For each image in the batch\n",
    "for i in range(batch_size):\n",
    "    problematic_spots = []\n",
    "    # problematic_spot_found = False\n",
    "\n",
    "    # For each pixel in the image\n",
    "    for y in range(true_values_denorm.shape[0]):\n",
    "        for x in range(true_values_denorm.shape[1]):\n",
    "            if realMask[i, y, x] != 0: # Only consider the pixel if it's not masked\n",
    "                pixel = true_values_denorm[i, y, x]\n",
    "\n",
    "                # Get the values of the neighbors\n",
    "                neighbors_mask = realMask[i, max(0, y-1):min(y+2, true_values_denorm.shape[0]), max(0, x-1):min(x+2, true_values_denorm.shape[1])]\n",
    "                neighbors_values = true_values_denorm[i, max(0, y-1):min(y+2, true_values_denorm.shape[0]), max(0, x-1):min(x+2, true_values_denorm.shape[1])]\n",
    "                neighbors_values[neighbors_mask == 0] = np.nan  # Replace masked values with np.nan\n",
    "\n",
    "                # Calculate the max difference\n",
    "                max_diff = np.nanmax(np.abs(neighbors_values - pixel)) if np.count_nonzero(~np.isnan(neighbors_values)) > 0 else 0\n",
    "\n",
    "                # If the max difference is greater than a tot amount, it's a problematic spot\n",
    "                if max_diff > 5:\n",
    "                    print(\"Sample n\", i+1, \", date:\", dates[i])\n",
    "                    print(f\"Problematic spot found in position ({y}, {x}), max difference: {max_diff}\")\n",
    "                    print(\"Adjacent values:\")\n",
    "                    print(neighbors_values)\n",
    "\n",
    "                    # Set the flag to True and store the coordinates of the problematic spot\n",
    "                    # problematic_spot_found = True\n",
    "                    problematic_spots.append((x, y))\n",
    "\n",
    "    # #If a problematic spot was found, plot the error image and the error image with the problematic spots marked\n",
    "    # if problematic_spot_found:\n",
    "    #     fig, axs = plt.subplots(1, 2, figsize=(24, 12))\n",
    "    #     # Plot the error image\n",
    "    #     axs[0].imshow(errors[i], cmap='jet')\n",
    "    #     axs[0].set_title(f\"Error map - Batch {i+1}\")\n",
    "    #     # Plot the error image with the problematic spots marked\n",
    "    #     axs[1].imshow(errors[i], cmap='jet')\n",
    "    #     axs[1].scatter(*zip(*problematic_spots), color='magenta')  # Scatter plot of the problematic spots\n",
    "    #     axs[1].set_title(f\"Error map - Batch {i+1} (Problematic spots marked)\")\n",
    "\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATION OVER DATASET - Check for problematic spots in real images\n",
    "\n",
    "def calculate_spatial_variation(sample, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the spatial variation for each pixel by comparing it with its neighbors\n",
    "    and return the average spatial variation for the sample.\n",
    "    \"\"\"\n",
    "    height, width = sample.shape\n",
    "    spatial_variations = np.zeros((height, width))\n",
    "    max_variation_in_sample = 0\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = sample[y, x]\n",
    "            neighbors_values = sample[max(0, y-1):min(y+2, height), max(0, x-1):min(x+2, width)]\n",
    "            max_diff = np.nanmax(np.abs(neighbors_values - pixel)) if np.count_nonzero(~np.isnan(neighbors_values)) > 0 else 0\n",
    "            spatial_variations[y, x] = max_diff\n",
    "            \n",
    "            if max_diff > threshold:  # input threshold for high spatial variation\n",
    "                print(f\"High spatial variation found in position ({y}, {x}), max difference: {max_diff}\")\n",
    "            if max_diff > max_variation_in_sample:\n",
    "                max_variation_in_sample = max_diff\n",
    "\n",
    "    # Calculate the average spatial variation for the sample\n",
    "    average_spatial_variation = np.nanmean(spatial_variations)\n",
    "    return average_spatial_variation, max_variation_in_sample\n",
    "\n",
    "treshold = 5                        # Threshold considered high spatial variation\n",
    "average_spatial_variations = []\n",
    "samples_with_high_variation = 0\n",
    "highest_spatial_variation = 0\n",
    "dataset = msr_sst_array   # Dataset to analyze\n",
    "\n",
    "# Iterate over each sample in the dataset\n",
    "for i in range(dataset.shape[0]):\n",
    "    #print(f\"Analyzing sample {i+1}\")\n",
    "    average_variation, max_variation_in_sample = calculate_spatial_variation(dataset[i, :, :], treshold)\n",
    "    average_spatial_variations.append(average_variation)\n",
    "    #print(f\"Average spatial variation for sample {i+1}: {average_variation}\")\n",
    "    \n",
    "    if max_variation_in_sample > treshold:  # Threshold for high spatial variation\n",
    "        samples_with_high_variation += 1\n",
    "    if max_variation_in_sample > highest_spatial_variation:\n",
    "        highest_spatial_variation = max_variation_in_sample\n",
    "\n",
    "# Calculate the overall average spatial variation\n",
    "overall_average_variation = np.mean(average_spatial_variations)\n",
    "print(f\"Overall average spatial variation: {overall_average_variation}\")\n",
    "print(f\"Number of samples with high spatial variation: {samples_with_high_variation}\")\n",
    "print(f\"Highest spatial variation in dataset: {highest_spatial_variation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if erroneous dates in dincae data (11/11/10 and 11/11/11) are the same in the real TERRA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dincae_coords = (12, 19, 40, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "#med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "terra10 = xr.open_dataset('dati/mist/old/dincae/TERRA_MODIS.20111110.L3m.DAY.SST4.sst4.4km.nc')\n",
    "#terra10\n",
    "terra10 = terra10['sst4']\n",
    "d10 = terra10.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "d10 = d10.values\n",
    "print(d10.shape)\n",
    "\n",
    "terra11 = xr.open_dataset('dati/mist/old/dincae/TERRA_MODIS.20111111.L3m.DAY.SST4.sst4.4km.nc')\n",
    "#terra11\n",
    "terra11 = terra11['sst4']\n",
    "d11 = terra11.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "d11 = d11.values\n",
    "print(d11.shape)\n",
    "\n",
    "terra12 = xr.open_dataset('dati/mist/old/dincae/TERRA_MODIS.20111112.L3m.DAY.SST4.sst4.4km.nc')\n",
    "#terra12\n",
    "terra12 = terra12['sst4']\n",
    "d12 = terra12.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "d12 = d12.values\n",
    "print(d12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the sst4\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# vmin = min(np.nanmin(msrc_sst[3235]), np.nanmin(msrc_sst[3236]), np.nanmin(d10), np.nanmin(d11))\n",
    "# vmax = max(np.nanmax(msrc_sst[3235]), np.nanmax(msrc_sst[3236]), np.nanmax(d10), np.nanmax(d11))\n",
    "vmin = min(np.nanmin(d10), np.nanmin(d11))\n",
    "vmax = max(np.nanmax(d10), np.nanmax(d11))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Dincae - 2011-11-10')\n",
    "plt.imshow(msrc_sst[3235], origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('Terra MODIS (night) - 2011-11-10')\n",
    "plt.imshow(d10, vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title('Dincae - 2011-11-11')\n",
    "plt.imshow(msrc_sst[3236], origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title('Terra MODIS (night) - 2011-11-11')\n",
    "plt.imshow(d11, vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the sst4\n",
    "plt.figure(figsize=(10, 4))\n",
    "vmin = min(np.nanmin(d12), np.nanmin(msrc_sst[3237]))\n",
    "vmax = max(np.nanmax(d12), np.nanmax(msrc_sst[3237]))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Dincae - 2011-11-12')\n",
    "plt.imshow(msrc_sst[3237], origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Terra MODIS (night) - 2011-11-12')\n",
    "plt.imshow(d12, vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataArray to numpy array and flatten\n",
    "msrc_sst_flat = msrc_sst[3237].values\n",
    "msrc_sst_flat = np.flip(msrc_sst_flat, axis=0)\n",
    "msrc_sst_flat = msrc_sst_flat.flatten()\n",
    "d12_flat = d12.flatten()\n",
    "\n",
    "# Create masks for NaN values\n",
    "mask_msrc_sst = np.isnan(msrc_sst_flat)\n",
    "mask_d12 = np.isnan(d12_flat)\n",
    "\n",
    "# Create masks for non-NaN values\n",
    "non_nan_mask_msrc_sst = ~mask_msrc_sst\n",
    "non_nan_mask_d12 = ~mask_d12\n",
    "\n",
    "# Create a mask for points where both matrices have non-NaN values\n",
    "non_nan_mask = non_nan_mask_msrc_sst & non_nan_mask_d12\n",
    "\n",
    "# Compare the non-NaN values in the two matrices\n",
    "are_values_equal = np.array_equal(msrc_sst_flat[non_nan_mask], d12_flat[non_nan_mask])\n",
    "\n",
    "print(\"The non-NaN values in the two matrices are equal:\", are_values_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confront with terra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_coords = (-5, 36, 30, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "dincae_coords = (12, 19, 40, 46)  # (lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "# tmask = xr.open_dataset('dati/mist/tmask_interpolated.nc')\n",
    "# ocean_mask = tmask['tmask']   # Extract the sst data\n",
    "# ocean_mask = ocean_mask.sel(lat=slice(None, None, -1))   # Flip the latitude axis to match the data\n",
    "# ditalymask = ocean_mask.sel(lon=slice(dincae_coords[0], dincae_coords[1]), lat=slice(dincae_coords[3], dincae_coords[2]))\n",
    "# ditalymask = ditalymask.astype(bool)\n",
    "# plt.imshow(ditalymask)\n",
    "# plt.show()\n",
    "# print('ditalymask shape:', ditalymask.shape)\n",
    "\n",
    "#Alternative: mask from the dincae dataset itself\n",
    "ditalymask = msr_mask = modis_sst_revlat['mask'].values\n",
    "ditalymask = ditalymask.astype(bool)\n",
    "ditalymask = np.flip(ditalymask, axis=0)    #Vertical flip\n",
    "print('ditalymask shape:', ditalymask.shape)\n",
    "plt.imshow(ditalymask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset creation\n",
    "\n",
    "# Get a list of all .nc files in the directories and combine all the file lists into one list\n",
    "all_files = glob.glob('dati/mist/dincae/terra/*.nc')\n",
    "\n",
    "# Datasets and dates lists (and quality?)\n",
    "dataset_t = []; date_t = []\n",
    "qual_t = []\n",
    "\n",
    "for file in all_files:\n",
    "    ds = xr.open_dataset(file)\n",
    "\n",
    "    data = ds['sst4'].values\n",
    "    data = np.where(ditalymask, data, np.nan)   # Apply the ditalymask\n",
    "\n",
    "    qual = ds['qual_sst4'].values\n",
    "    qual = np.where(ditalymask, qual, np.nan)   # Apply the ditalymask\n",
    "    \n",
    "    date = pd.to_datetime(ds.attrs['product_name'].split('.')[1]).date()\n",
    "    date = np.array(date, dtype='datetime64[D]')\n",
    "    date = date.astype(int)\n",
    "    \n",
    "    dataset_t.append(data)\n",
    "    date_t.append(date)\n",
    "    qual_t.append(qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a numpy array\n",
    "\n",
    "dataset_t = np.array(dataset_t)\n",
    "date_t = np.array(date_t)\n",
    "qual_t = np.array(qual_t)\n",
    "\n",
    "print(dataset_t.shape)\n",
    "print(date_t.shape)\n",
    "print(qual_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"msr_sst_t.shape:\", msr_sst_t.shape)\n",
    "print(\"msrc_sst_t.shape:\", msrc_sst_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaaaaaaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_sst_t_array = np.load('dati/mist/dincae/msr_sst_t_array.npy')\n",
    "msrc_sst_t_array = np.load('dati/mist/dincae/msrc_sst_t_array.npy')\n",
    "\n",
    "print(\"msr_sst_t_array.shape:\", msr_sst_t_array.shape)\n",
    "print(\"msrc_sst_t_array.shape:\", msrc_sst_t_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot msr_sst_t and msrc_sst_t\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(msr_sst_t_array[22], cmap='viridis')\n",
    "plt.title('msr_sst_t')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(msrc_sst_t_array[22], cmap='viridis')\n",
    "plt.title('msrc_sst_t')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut a sample from msr_sst_t_array and msrc_sst_t_array into a 128x128 image\n",
    "# the cut should be from the top for the y length, and offset 10 pixels from the right for the x length\n",
    "\n",
    "cut_msr_sst_t = msr_sst_t_array[:, :128, 30:158]\n",
    "cut_msrc_sst_t = msrc_sst_t_array[:, :128, 30:158]\n",
    "\n",
    "print(cut_msr_sst_t.shape)\n",
    "print(cut_msrc_sst_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cut_msr_sst_t and cut_msrc_sst_t\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cut_msr_sst_t[22], cmap='viridis')\n",
    "plt.title('cut_msr_sst_t')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cut_msrc_sst_t[22], cmap='viridis')\n",
    "plt.title('cut_msrc_sst_t')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
